{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "import time"
      ],
      "metadata": {
        "id": "AVHrOlrVeb0y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to find P(Y=k), just do test_labels.where(k)/len(test_labels)\n",
        "# vectos_train will contain all the information I need to create the counting for each word\n",
        "# use the get_feature_names to create a dictionary to map to all counts\n",
        "# this dictionary would be contained in another dict that has the labels as keys\n",
        "# to find P(xj,k), find the indices where test_labels = (k), then find"
      ],
      "metadata": {
        "id": "ILJgBzQUkOfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Handle cases where two examples are permutations of another\n",
        "# TODO: Handle laplace smoothing, i.e. word from corpus not in word list"
      ],
      "metadata": {
        "id": "tyztECAW9XOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#' '.join(map(str, train_corpus[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NFFQb9OohZ-E",
        "outputId": "50fb9767-d88b-420a-cdc8-cb0dce72c562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is the first document.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NB():\n",
        "  def __init__(self):\n",
        "    self.vectorizer = CountVectorizer(binary = True)\n",
        "\n",
        "  # currently train_corpus expects a np array containing a list of strings, not array of words, nxm\n",
        "  # test_label is an nx1 array\n",
        "  def learn(self, train_corpus, test_labels):\n",
        "    assert len(train_corpus) == len(test_labels)\n",
        "    assert type(train_corpus) == type(test_labels) == np.ndarray\n",
        "\n",
        "    vectors_train  = self.vectorizer.fit_transform(train_corpus).todense()\n",
        "    self.word_list   = self.vectorizer.get_feature_names_out()\n",
        "    self.num_samples = len(test_labels)\n",
        "\n",
        "    unique, counts   = np.unique(test_labels, return_counts=True)\n",
        "    self.label_count = dict(zip(unique, counts))\n",
        "    self.labels      = unique\n",
        "\n",
        "    self.word_count_given_label = {}\n",
        "    for label in self.labels:\n",
        "      indices = np.where(test_labels == label)[0]\n",
        "      tot_word_count = np.array(vectors_train[indices].sum(axis=0))[0]\n",
        "      self.word_count_given_label[label] = {self.word_list[i] : tot_word_count[i] for i in range(len(tot_word_count))}\n",
        "      # print(label, self.word_count_given_label[label])\n",
        "\n",
        "  # Assuming test_corpus is 2-d array where each test sample is an array of tokens\n",
        "  def predict(self, test_corpus):\n",
        "    assert type(test_corpus) == np.ndarray\n",
        "\n",
        "    predictions = []\n",
        "    for corpus in test_corpus:\n",
        "\n",
        "      best_label = ''\n",
        "      best_prob  = -1000\n",
        "\n",
        "      for label in self.labels:\n",
        "        p_of_y = self.label_count[label]/self.num_samples\n",
        "\n",
        "        p_of_x_given_y = 1\n",
        "\n",
        "        for word in self.word_list:\n",
        "          if word in corpus:\n",
        "            xj = 1\n",
        "          else:\n",
        "            xj = 0\n",
        "\n",
        "          theta_xj_k      = (self.word_count_given_label[label][word] + 1) / (self.label_count[label] + len(self.labels))\n",
        "          p_of_x_given_y *= (theta_xj_k**(xj) * (1-theta_xj_k)**(1-xj))\n",
        "          # print(label, word, p_of_x_given_y, theta_xj_k, (theta_xj_k**(xj) * (1-theta_xj_k)**(1-xj)))\n",
        "\n",
        "        unseen_words = [new_word for new_word in corpus if new_word not in self.word_list]\n",
        "        for word in unseen_words:\n",
        "          p_of_x_given_y *= 1/(self.label_count[label] + len(self.labels))\n",
        "\n",
        "        p_of_y_given_x = np.log(p_of_y * p_of_x_given_y)\n",
        "        # print(label, p_of_y_given_x)\n",
        "\n",
        "        # print(p_of_y_given_x, best_prob)\n",
        "        if p_of_y_given_x > best_prob:\n",
        "          best_prob = p_of_y_given_x\n",
        "          best_label = label\n",
        "\n",
        "      predictions.append(best_label)\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "tJypvj7ZnfWY"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "     'Is this the first document?',]\n",
        "test_labels = np.array(['1', '2', '3', '4'])\n",
        "train_corpus = np.array(train_corpus)\n",
        "test_corpus = np.array([['harro', 'first', 'pink', 'third',]])\n",
        "model = NB()\n",
        "model.learn(train_corpus, test_labels)\n",
        "model.predict(test_corpus)"
      ],
      "metadata": {
        "id": "qo7BKNgek7NV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a89e2d-85e9-4f53-c701-66484ef35819"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "X_train = np.array([\n",
        "    \"I love this movie\",\n",
        "    \"This movie is great\",\n",
        "    \"A movie like this is great\",\n",
        "    \"I hate this movie\",\n",
        "    \"This movie is terrible\"\n",
        "])\n",
        "\n",
        "# Corresponding labels\n",
        "y_train = np.array([1, 1, 1, 0, 0])  # 1 for positive sentiment, 0 for negative sentiment\n",
        "\n",
        "\n",
        "model = NB()\n",
        "model.learn(X_train, y_train)\n",
        "X_test = np.array([\n",
        "    \"I love this movie, but terrible in some parts d dfa fa sf asdf adf dasf asdf df df dfd\",\n",
        "    \"I hate this great movie\",\n",
        "    \"This movie is terrible\"\n",
        "])\n",
        "\n",
        "\n",
        "for instance in X_test:\n",
        "  print(model.predict(np.array([instance.split()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jmTZkw2lgUe",
        "outputId": "3e7c2cfc-1c7a-47d0-e2b5-bd48acc8f7e4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "[1]\n",
            "[0]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}